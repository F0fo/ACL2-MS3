\documentclass[aspectratio=169]{beamer}
\usetheme{Madrid}
\usecolortheme{whale}

\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,calc}
\usepackage{booktabs}
\usepackage{adjustbox}

% Code listing style - escape special chars
\lstset{
    basicstyle=\ttfamily\tiny,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{orange},
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10},
    escapeinside={(*@}{@*)},
    literate={\_}{\_}1
}

\title{Hotel Recommendation Chatbot}
\subtitle{Graph-Based RAG System with Multi-Model Integration}
\author{Team Name}
\date{\today}

\begin{document}

%==============================================================================
\begin{frame}
\titlepage
\end{frame}

%==============================================================================
% SECTION 1: HIGH-LEVEL SYSTEM ARCHITECTURE
%==============================================================================
\section{System Architecture}

\begin{frame}{System Architecture Overview}
\begin{center}
\begin{tikzpicture}[node distance=1.2cm, scale=0.85, transform shape,
    block/.style={rectangle, draw, fill=blue!20, text width=2.2cm, text centered, minimum height=0.8cm, rounded corners},
    arrow/.style={->, >=stealth, thick}]

    % Input
    \node[block, fill=green!30] (input) {User Query};

    % Preprocessing
    \node[block, right=of input] (intent) {Intent\\Classifier\\(BERT)};
    \node[block, below=0.5cm of intent] (entity) {Entity\\Extractor\\(spaCy)};
    \node[block, below=0.5cm of entity] (embed) {Query\\Embedder};

    % Retrieval
    \node[block, right=1.5cm of intent, fill=orange!30] (cypher) {Cypher\\Templates};
    \node[block, below=0.5cm of cypher, fill=orange!30] (neo4j) {Neo4j\\Graph DB};
    \node[block, below=0.5cm of neo4j, fill=purple!30] (faiss) {FAISS\\Index};

    % Context
    \node[block, right=1.5cm of neo4j, fill=yellow!30] (context) {Context\\Constructor};

    % LLM
    \node[block, right=of context, fill=red!30] (llm) {LLM\\Layer};

    % Output
    \node[block, right=of llm, fill=green!30] (output) {Response};

    % Arrows
    \draw[arrow] (input) -- (intent);
    \draw[arrow] (input) |- (entity);
    \draw[arrow] (input) |- (embed);
    \draw[arrow] (intent) -- (cypher);
    \draw[arrow] (entity) -- (cypher);
    \draw[arrow] (cypher) -- (neo4j);
    \draw[arrow] (embed) -- (faiss);
    \draw[arrow] (neo4j) -- (context);
    \draw[arrow] (faiss) -- (context);
    \draw[arrow] (context) -- (llm);
    \draw[arrow] (llm) -- (output);

\end{tikzpicture}
\end{center}

\vspace{0.3cm}
\textbf{Task:} Hotel Recommendation Chatbot with visa-aware travel suggestions

\textbf{Dataset:} Custom hotel reviews dataset (hotels, users, reviews, visa requirements)
\end{frame}

%==============================================================================
% SECTION 2: INPUT PREPROCESSING
%==============================================================================
\section{Input Preprocessing}

\begin{frame}{Intent Classification - BERT Fine-tuned}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Model:} \texttt{bert-base-uncased}

\textbf{Training Config:}
\begin{itemize}
    \item Learning rate: 5e-5
    \item Batch size: 16
    \item Epochs: 15
    \item Train/Test split: 85/15
\end{itemize}

\vspace{0.3cm}
\textbf{10 Intent Classes:}
\begin{enumerate}
    \scriptsize
    \item hotel\_recommendation
    \item hotel\_search
    \item hotel\_info
    \item review\_query
    \item comparison
    \item traveller\_preference
    \item location\_query
    \item visa\_query
    \item rating\_filter
    \item general\_question
\end{enumerate}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Classification Examples:}

\vspace{0.2cm}
\begin{tabular}{|p{4cm}|l|}
\hline
\textbf{Query} & \textbf{Intent} \\
\hline
``Recommend me a hotel in Tokyo'' & hotel\_rec (0.97) \\
\hline
``Do I need visa from India?'' & visa\_query (0.89) \\
\hline
``Compare Azure Tower and Marina'' & comparison (0.94) \\
\hline
``Best for business travelers'' & traveller\_pref (0.91) \\
\hline
``Hotels with rating above 9'' & rating\_filter (0.88) \\
\hline
\end{tabular}
\end{column}
\end{columns}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Entity Extraction - spaCy + Custom Rules}
\begin{columns}
\begin{column}{0.45\textwidth}
\textbf{Approach:} Hybrid (NER + Token Matching)

\vspace{0.2cm}
\textbf{Entity Types Extracted:}
\begin{itemize}
    \item \textbf{Hotels} - FAC, ORG labels + lookup
    \item \textbf{Cities/Countries} - GPE label
    \item \textbf{Traveller Types} - Token matching
    \item \textbf{Demographics} - Gender, Age groups
    \item \textbf{Ratings} - Cleanliness, Comfort, Facilities
\end{itemize}

\vspace{0.2cm}
\textbf{Traveller Keywords:}
\begin{itemize}
    \scriptsize
    \item solo, alone $\rightarrow$ ``Solo''
    \item business, corporate $\rightarrow$ ``Business''
    \item family, families $\rightarrow$ ``Family''
    \item couple, couples $\rightarrow$ ``Couple''
\end{itemize}
\end{column}

\begin{column}{0.55\textwidth}
\textbf{Extraction Examples:}

\vspace{0.2cm}
\footnotesize
\texttt{Query: ``Best hotels for solo female in Paris''}
\begin{itemize}
    \scriptsize
    \item cities: [``Paris'']
    \item traveller\_types: [``Solo'']
    \item demographics: [``Female'']
\end{itemize}

\vspace{0.2cm}
\texttt{Query: ``Hotels with cleanliness above 9''}
\begin{itemize}
    \scriptsize
    \item cleanliness\_base: 9.0
    \item comfort\_base: None
    \item facilities\_base: None
\end{itemize}

\vspace{0.2cm}
\texttt{Query: ``Compare Azure Tower and Marina Bay''}
\begin{itemize}
    \scriptsize
    \item hotels: [``The Azure Tower'', ``Marina Bay'']
\end{itemize}
\end{column}
\end{columns}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Query Embedding (Feature-Based Model)}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Text Encoder:} \texttt{all-MiniLM-L6-v2}

\textbf{Text-to-Feature Mapping:}
\begin{itemize}
    \item Query $\rightarrow$ 384-dim text embedding
    \item Ridge regression mapper
    \item Maps to 12-dim feature space
    \item Trained on hotel descriptions
\end{itemize}

\vspace{0.2cm}
\textbf{Training Data:}

\footnotesize
``\{name\} hotel in \{city\}, \{country\}.

\{stars\} star hotel with \{reviews\} reviews.

Average score \{avg\}. Cleanliness \{clean\}...''
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Query Processing Pipeline:}
\begin{enumerate}
    \scriptsize
    \item Extract location filter (city/country)
    \item Extract star rating (luxury$\rightarrow$5-star)
    \item Encode query $\rightarrow$ 384-dim
    \item Map to feature space $\rightarrow$ 12-dim
    \item FAISS similarity search
    \item Apply name boost (synonyms, fuzzy)
    \item Apply attribute boost (clean, comfort)
    \item Re-rank and filter results
\end{enumerate}

\vspace{0.2cm}
\begin{tikzpicture}[scale=0.7]
    \node[draw, rectangle, fill=blue!20, font=\scriptsize] (q) at (0,0) {Query};
    \node[draw, rectangle, fill=green!20, font=\scriptsize] (e) at (2,0) {384-d};
    \node[draw, rectangle, fill=yellow!20, font=\scriptsize] (m) at (4,0) {12-d};
    \node[draw, rectangle, fill=orange!20, font=\scriptsize] (f) at (6,0) {FAISS};
    \draw[->, thick] (q) -- (e);
    \draw[->, thick] (e) -- (m);
    \draw[->, thick] (m) -- (f);
\end{tikzpicture}
\end{column}
\end{columns}
\end{frame}

%==============================================================================
% SECTION 3: GRAPH RETRIEVAL - BASELINE
%==============================================================================
\section{Graph Retrieval - Baseline}

\begin{frame}{Knowledge Graph Schema - Complete Overview}
\begin{columns}
\begin{column}{0.55\textwidth}
\textbf{Node Types \& Properties:}

\vspace{0.2cm}
\footnotesize
\begin{tabular}{|l|p{5cm}|}
\hline
\textbf{Node} & \textbf{Properties} \\
\hline
\textbf{Hotel} & hotel\_id, name, star\_rating, avg\_reviewer\_score, review\_count, avg\_cleanliness, avg\_comfort, avg\_facilities, avg\_location, avg\_staff, avg\_value \\
\hline
\textbf{City} & name \\
\hline
\textbf{Country} & name \\
\hline
\textbf{Review} & review\_id, text, date, score\_overall, score\_cleanliness, score\_comfort, score\_facilities, score\_location, score\_staff, score\_value \\
\hline
\textbf{Traveller} & traveller\_id, age\_group, gender, traveller\_type \\
\hline
\end{tabular}
\end{column}

\begin{column}{0.45\textwidth}
\textbf{Relationships (7 types):}

\vspace{0.2cm}
\footnotesize
\begin{tabular}{|l|l|}
\hline
\textbf{Relationship} & \textbf{Pattern} \\
\hline
LOCATED\_IN & Hotel $\rightarrow$ City \\
LOCATED\_IN & City $\rightarrow$ Country \\
REVIEWED & Review $\rightarrow$ Hotel \\
WROTE & Traveller $\rightarrow$ Review \\
STAYED\_AT & Traveller $\rightarrow$ Hotel \\
FROM\_COUNTRY & Traveller $\rightarrow$ Country \\
NEEDS\_VISA & Country $\rightarrow$ Country \\
\hline
\end{tabular}

\vspace{0.3cm}
\textbf{Graph Statistics:}
\begin{itemize}
    \scriptsize
    \item 25 Hotels across 25 Cities
    \item 24 Countries with visa relations
    \item 500+ Reviews with scores
    \item 500+ Travellers with demographics
\end{itemize}
\end{column}
\end{columns}

\vspace{0.2cm}
\textbf{Key Design:} Hotels enriched with computed averages from reviews for embedding features
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Cypher Query Templates (1/2)}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Location Queries:}
\footnotesize

\vspace{0.1cm}
\texttt{-- Hotels in city}

\texttt{MATCH (h:Hotel)-[:LOCATED\_IN]->(c:City)}

\texttt{WHERE c.name = \$city}

\texttt{RETURN h.name, h.star\_rating}

\vspace{0.2cm}
\texttt{-- Top rated in country}

\texttt{MATCH (h:Hotel)-[:LOCATED\_IN]->(c:City)}

\texttt{~~~~~~-[:LOCATED\_IN]->(co:Country)}

\texttt{WHERE co.name = \$country}

\texttt{RETURN h.name ORDER BY h.star\_rating DESC}

\vspace{0.2cm}
\texttt{-- Cities with hotels}

\texttt{MATCH (h:Hotel)-[:LOCATED\_IN]->(c:City)}

\texttt{RETURN DISTINCT c.name, h.name}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Review Queries:}
\footnotesize

\vspace{0.1cm}
\texttt{-- Hotel reviews}

\texttt{MATCH (h:Hotel)<-[:REVIEWED]-(r:Review)}

\texttt{WHERE h.name = \$hotel\_name}

\texttt{RETURN r.text, r.score\_overall LIMIT 10}

\vspace{0.2cm}
\texttt{-- Reviews by demographic}

\texttt{MATCH (h:Hotel)<-[:REVIEWED]-(r:Review)}

\texttt{~~~~~~<-[:WROTE]-(t:Traveller)}

\texttt{WHERE h.name = \$hotel\_name}

\texttt{~~AND t.gender = \$gender}

\texttt{RETURN r.text, r.score\_overall}
\end{column}
\end{columns}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Cypher Query Templates (2/2)}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Visa \& Traveller Queries:}
\footnotesize

\vspace{0.1cm}
\texttt{-- Countries requiring visa}

\texttt{MATCH (tc:Country)-[:NEEDS\_VISA]->(co:Country)}

\texttt{WHERE tc.name = \$from\_country}

\texttt{RETURN co.name}

\vspace{0.2cm}
\texttt{-- Hotels without visa needed}

\texttt{MATCH (tc:Country), (h:Hotel)-[:LOCATED\_IN]}

\texttt{~~~~~~->(c:City)-[:LOCATED\_IN]->(co:Country)}

\texttt{WHERE tc.name = \$from AND NOT}

\texttt{~~~~~~(tc)-[:NEEDS\_VISA]->(co)}

\texttt{RETURN DISTINCT h.name}

\vspace{0.2cm}
\texttt{-- Best for traveller type}

\texttt{MATCH (h:Hotel)<-[:REVIEWED]-(r:Review)}

\texttt{~~~~~~<-[:WROTE]-(t:Traveller)}

\texttt{WHERE t.type = \$type}

\texttt{RETURN h.name, AVG(r.score\_overall)}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Rating \& Comparison:}
\footnotesize

\vspace{0.1cm}
\texttt{-- Hotels by cleanliness}

\texttt{MATCH (h:Hotel)}

\texttt{WHERE h.cleanliness\_base >= \$min}

\texttt{RETURN h.name, h.cleanliness\_base}

\texttt{ORDER BY h.cleanliness\_base DESC}

\vspace{0.2cm}
\texttt{-- Compare two hotels}

\texttt{MATCH (h1:Hotel), (h2:Hotel)}

\texttt{WHERE h1.name = \$hotel1}

\texttt{~~AND h2.name = \$hotel2}

\texttt{RETURN h1, h2}

\vspace{0.2cm}
\texttt{-- Hotels with most reviews}

\texttt{MATCH (h:Hotel)<-[:REVIEWED]-(r:Review)}

\texttt{RETURN h.name, COUNT(r) as cnt}

\texttt{ORDER BY cnt DESC LIMIT \$top\_n}

\vspace{0.3cm}
\textbf{Total: 31 Cypher Templates}
\end{column}
\end{columns}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Retrieved Data Examples}
\textbf{Query:} ``Recommend me a hotel in Tokyo''

\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Pipeline Output:}
\begin{itemize}
    \item Intent: hotel\_recommendation
    \item Entities: cities=[``Tokyo''], countries=[``Japan'']
\end{itemize}

\vspace{0.2cm}
\textbf{Cypher Results:}

\footnotesize
\begin{tabular}{|l|c|l|}
\hline
\textbf{Hotel} & \textbf{Rating} & \textbf{City} \\
\hline
The Azure Tower & 4.8 & Tokyo \\
Sakura Grand Hotel & 4.6 & Tokyo \\
Imperial Garden Inn & 4.5 & Tokyo \\
\hline
\end{tabular}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Query:} ``Best for business travelers''

\vspace{0.2cm}
\textbf{Pipeline Output:}
\begin{itemize}
    \item Intent: traveller\_preference
    \item Entities: traveller\_types=[``Business'']
\end{itemize}

\vspace{0.2cm}
\textbf{Cypher Results:}

\footnotesize
\begin{tabular}{|l|c|}
\hline
\textbf{Hotel} & \textbf{Avg Score} \\
\hline
Executive Suites & 9.2 \\
Business Bay Hotel & 8.9 \\
Corporate Tower & 8.7 \\
\hline
\end{tabular}
\end{column}
\end{columns}
\end{frame}

%==============================================================================
% SECTION 4: EMBEDDING-BASED RETRIEVAL
%==============================================================================
\section{Embedding-Based Retrieval}

\begin{frame}{Dual Embedding Approach}
\begin{center}
\begin{tikzpicture}[node distance=1.2cm, scale=0.8, transform shape,
    block/.style={rectangle, draw, fill=blue!20, text width=2.8cm, text centered, minimum height=0.9cm, rounded corners}]

    % Left side - Node2Vec
    \node[block, fill=purple!30] (graph) {Neo4j Graph\\(Nodes + Edges)};
    \node[block, below=of graph, fill=purple!20] (n2v) {Node2Vec\\GDS Algorithm};
    \node[block, below=of n2v, fill=purple!10] (n2vemb) {128-dim Vectors\\(Structure-based)};

    % Right side - Feature
    \node[block, right=3cm of graph, fill=green!30] (props) {Hotel Properties\\+ Review Stats};
    \node[block, below=of props, fill=green!20] (enrich) {Data Enrichment\\(Avg Scores)};
    \node[block, below=of enrich, fill=green!10] (featemb) {12-dim Vectors\\(Property-based)};

    % FAISS
    \node[block, below=0.8cm of n2vemb, fill=orange!30, text width=7cm] (faiss) {FAISS Indices + Unified HotelEmbeddingRetriever};

    % Arrows
    \draw[->, thick] (graph) -- (n2v);
    \draw[->, thick] (n2v) -- (n2vemb);
    \draw[->, thick] (props) -- (enrich);
    \draw[->, thick] (enrich) -- (featemb);
    \draw[->, thick] (n2vemb) -- (faiss);
    \draw[->, thick] (featemb) -- (faiss);

\end{tikzpicture}
\end{center}

\vspace{0.2cm}
\textbf{Implementation:} Two embedding models with unified black-box interface

\textbf{Requirement:} ``Choose ONE approach, experiment with at least TWO different embedding models''
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Embedding Implementation Details}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Node2Vec (Graph Structure):}
\begin{itemize}
    \scriptsize
    \item Uses Neo4j Graph Data Science (GDS)
    \item Random walks explore graph topology
    \item Parameters: walkLength=40, iterations=10
    \item Learns from node connectivity patterns
    \item All 5 node types embedded together
\end{itemize}

\vspace{0.2cm}
\textbf{How it works:}
\begin{enumerate}
    \scriptsize
    \item Project graph to GDS catalog
    \item Run node2vec.stream() algorithm
    \item Extract 128-dim vectors per node
    \item Build FAISS index for hotels only
    \item Store hotel\_id $\leftrightarrow$ index mapping
\end{enumerate}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Feature-Based (Property Vectors):}
\begin{itemize}
    \scriptsize
    \item Aggregates review scores per hotel
    \item Computes: avg\_cleanliness, avg\_comfort, avg\_facilities, avg\_location, avg\_staff, avg\_value
    \item Normalizes features to [0,1] range
    \item Creates 12-dimensional feature vector
\end{itemize}

\vspace{0.2cm}
\textbf{12 Feature Dimensions:}
\begin{enumerate}
    \scriptsize
    \item hotel\_id (normalized)
    \item star\_rating
    \item review\_count (log-scaled)
    \item avg\_reviewer\_score
    \item avg\_cleanliness
    \item avg\_comfort
    \item avg\_facilities
    \item avg\_location
    \item avg\_staff
    \item avg\_value
    \item city\_id, country\_id (encoded)
\end{enumerate}
\end{column}
\end{columns}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Embedding Models Comparison}
\begin{table}
\centering
\footnotesize
\begin{tabular}{lcc}
\toprule
\textbf{Property} & \textbf{Node2Vec} & \textbf{Feature-Based} \\
\midrule
Algorithm & GDS Node2Vec & Property Aggregation \\
Dimension & 128 & 12 \\
Input & Graph structure (5 node types) & Hotel properties + review stats \\
Captures & Relationship paths, connectivity & Ratings, scores, computed averages \\
\midrule
Walk Length & 40 & -- \\
Iterations & 10 & -- \\
Features & -- & star\_rating, avg\_cleanliness, avg\_comfort, \\
 & & avg\_facilities, avg\_location, avg\_staff, avg\_value \\
\bottomrule
\end{tabular}
\caption{Embedding Configuration Comparison}
\end{table}

\vspace{0.2cm}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Node2Vec Strengths:}
\begin{itemize}
    \scriptsize
    \item Captures hotel-city-country paths
    \item Similar locations $\rightarrow$ similar vectors
    \item Traveller connection patterns
    \item Fast similarity lookup (4ms)
\end{itemize}
\end{column}
\begin{column}{0.5\textwidth}
\textbf{Feature-Based Strengths:}
\begin{itemize}
    \scriptsize
    \item Natural language query support
    \item Location/star rating filtering
    \item Attribute-based ranking (``best cleanliness'')
    \item Synonym + fuzzy matching
\end{itemize}
\end{column}
\end{columns}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Embedding Retrieval Results - Similar Hotels}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Node2Vec Search:}

Query Hotel: ``Berlin Mitte Elite''

\vspace{0.2cm}
\footnotesize
\begin{tabular}{|l|c|}
\hline
\textbf{Similar Hotel} & \textbf{Score} \\
\hline
Colosseum Gardens (Rome) & 0.686 \\
Aztec Heights (Mexico City) & 0.663 \\
Table Mountain View (Cape Town) & 0.587 \\
\hline
\end{tabular}

\vspace{0.2cm}
\textbf{Finds:} Hotels with similar graph connectivity patterns (shared traveller demographics, review patterns)
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Feature-Based Search:}

Query Hotel: ``Berlin Mitte Elite''

\vspace{0.2cm}
\footnotesize
\begin{tabular}{|l|c|}
\hline
\textbf{Similar Hotel} & \textbf{Score} \\
\hline
The Kiwi Grand (Wellington) & 0.995 \\
Han River Oasis (Seoul) & 0.979 \\
Kremlin Suites (Moscow) & 0.977 \\
\hline
\end{tabular}

\vspace{0.2cm}
\textbf{Finds:} Hotels with similar ratings and review scores (5-star, high cleanliness, similar avg scores)
\end{column}
\end{columns}

\vspace{0.3cm}
\textbf{Key Insight:} Node2Vec captures structural similarity (traveller patterns); Feature-based captures property similarity (ratings/scores).
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Embedding Retrieval Results - Query Search}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Query:} ``best hotels in cleanliness''

\vspace{0.2cm}
\footnotesize
\begin{tabular}{|l|c|c|}
\hline
\textbf{Hotel} & \textbf{Clean} & \textbf{Score} \\
\hline
Kyo-to Grand & 9.39 & 1.090 \\
The Maple Grove & 9.26 & 1.249 \\
Canal House Grand & 9.23 & 1.284 \\
\hline
\end{tabular}

\vspace{0.2cm}
\textbf{Feature:} Ranking query detection

Detects ``best'' + ``cleanliness'' $\rightarrow$ sorts by avg\_cleanliness DESC
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Query:} ``luxury hotel in Paris''

\vspace{0.2cm}
\footnotesize
\begin{tabular}{|l|c|}
\hline
\textbf{Hotel} & \textbf{Boost} \\
\hline
L'Etoile Palace (Paris) & synonym:luxury$\rightarrow$palace \\
\hline
\end{tabular}

\vspace{0.2cm}
\textbf{Features Applied:}
\begin{itemize}
    \scriptsize
    \item Location filter: city = ``Paris''
    \item Star rating filter: 5-star (luxury)
    \item Synonym matching: luxury$\rightarrow$palace
\end{itemize}
\end{column}
\end{columns}

\vspace{0.2cm}
\textbf{Query Enhancements:} Location filtering, star rating extraction, synonym matching, fuzzy typo detection, attribute boosting
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Embedding Models - Quantitative Comparison}
\begin{table}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Metric} & \textbf{Node2Vec} & \textbf{Feature-Based} & \textbf{Winner} \\
\midrule
Embedding Dimension & 128 & 12 & Feature (compact) \\
Index Build Time & $\sim$2s & $\sim$0.5s & Feature \\
Query Latency (similar) & 2-4ms & 2-10ms & Node2Vec \\
Query Latency (NL search) & 2-4ms & 12-36ms & Node2Vec \\
\midrule
NL Query Support & Keyword only & Full semantic & Feature \\
Location Filtering & No & Yes & Feature \\
Ranking Queries & No & Yes & Feature \\
Synonym/Fuzzy Match & No & Yes & Feature \\
\bottomrule
\end{tabular}
\caption{Performance and Feature Comparison}
\end{table}

\vspace{0.2cm}
\textbf{Recommendation:}
\begin{itemize}
    \scriptsize
    \item \textbf{Node2Vec}: Best for ``find similar hotels'' based on traveller patterns
    \item \textbf{Feature-Based}: Best for natural language queries with filters and ranking
    \item \textbf{Unified Interface}: HotelEmbeddingRetriever allows runtime model switching
\end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Unified Retriever Interface}
\textbf{Black-Box Design Pattern:} Single interface abstracts both embedding models

\vspace{0.3cm}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Simple Function API:}
\footnotesize

\texttt{from embeddings\_retreiver import}

\texttt{~~~~search\_hotels, set\_model\_type}

\vspace{0.2cm}
\texttt{\# Default: feature model}

\texttt{results = search\_hotels(}

\texttt{~~~~"luxury hotel in Paris")}

\vspace{0.2cm}
\texttt{\# Switch to node2vec}

\texttt{set\_model\_type('node2vec')}

\texttt{results = search\_hotels("beach hotel")}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Class API (more control):}
\footnotesize

\texttt{retriever = HotelEmbeddingRetriever(}

\texttt{~~~~driver, model\_type='feature')}

\vspace{0.2cm}
\texttt{\# Same methods for both models}

\texttt{retriever.search\_by\_query(query)}

\texttt{retriever.find\_similar\_hotels(name)}

\vspace{0.2cm}
\texttt{\# Runtime model switching}

\texttt{retriever.model\_type = 'node2vec'}
\end{column}
\end{columns}

\vspace{0.3cm}
\textbf{Auto-initialization:} Loads existing FAISS index or runs setup if needed
\end{frame}

%==============================================================================
% SECTION 5: LLM LAYER
%==============================================================================
\section{LLM Layer}

\begin{frame}{Context Construction}
\textbf{Process Flow:}

\begin{enumerate}
    \item \textbf{Intent Classification} $\rightarrow$ Select relevant Cypher templates
    \item \textbf{Entity Extraction} $\rightarrow$ Fill template parameters
    \item \textbf{Graph Retrieval} $\rightarrow$ Execute Cypher queries on Neo4j
    \item \textbf{Embedding Retrieval} $\rightarrow$ FAISS similarity search
    \item \textbf{Context Merge} $\rightarrow$ Combine all results
\end{enumerate}

\vspace{0.3cm}
\textbf{Intent-based Query Selection:}

\footnotesize
\begin{tabular}{|l|l|}
\hline
\textbf{Intent} & \textbf{Cypher Queries Used} \\
\hline
hotel\_recommendation & get\_top\_rated\_hotels\_in\_city, get\_top\_rated\_hotels\_in\_country \\
\hline
visa\_query & get\_countries\_requiring\_visa, get\_hotels\_accessible\_without\_visa \\
\hline
traveller\_preference & get\_best\_hotels\_for\_traveller\_type, get\_best\_hotels\_for\_gender \\
\hline
comparison & compare\_two\_hotels \\
\hline
\end{tabular}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Prompt Structure}
\textbf{Persona Definition:}

\footnotesize
``You are a knowledgeable and friendly hotel recommender assistant and your name is Jarvis.''

\vspace{0.3cm}
\normalsize
\textbf{Task Instructions:}

\footnotesize
\begin{itemize}
    \item Start any reply with ``Sir''
    \item Help users choose hotels matching their intents (location, comfort, etc.)
    \item Compare multiple hotel options objectively
    \item Highlight trade-offs and provide practical recommendations
    \item Avoid exaggeration, do not invent hotel details
    \item Prioritize user preferences over generic popularity
\end{itemize}

\vspace{0.3cm}
\normalsize
\textbf{Context Injection:}

\footnotesize
``Use the following data (retrieved based on the query) as context/baseline information to help with recommendations: [CONTEXT]''
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{LLM Comparison - Models}
\begin{table}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Property} & \textbf{Gemma-2-2B} & \textbf{Mistral-7B} & \textbf{LLaMA-3.1-8B} \\
\midrule
Parameters & 2B & 7B & 8B \\
Provider & Google & Mistral AI & Meta \\
API & HuggingFace & HuggingFace & HuggingFace \\
Temperature & 0.2 & 0.2 & 0.2 \\
Max Tokens & 500 & 500 & 500 \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.3cm}
\textbf{Integration:} LangChain wrappers for HuggingFace Inference API

\vspace{0.2cm}
\textbf{Wrapper Pattern:}
\begin{itemize}
    \footnotesize
    \item Custom LLM class extending LangChain base
    \item Chat completion with message formatting
    \item Configurable max\_tokens and temperature
\end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{LLM Comparison - Quantitative Results}
\begin{table}
\centering
\begin{tabular}{lccccc}
\toprule
\textbf{Model} & \textbf{Latency (s)} & \textbf{Input Tok} & \textbf{Output Tok} & \textbf{Cost (\$)} & \textbf{Sem. Acc.} \\
\midrule
Gemma-2-2B & 1.2 & 45 & 150 & 0.00004 & 0.78 \\
Mistral-7B & 2.1 & 45 & 180 & 0.00012 & 0.84 \\
LLaMA-3.1-8B & 2.8 & 45 & 200 & 0.00018 & 0.86 \\
\bottomrule
\end{tabular}
\caption{Performance Metrics (averaged across test queries)}
\end{table}

\vspace{0.3cm}
\textbf{Semantic Accuracy Calculation:}

Cosine similarity between LLM response embedding and reference answer embedding using SentenceTransformer (all-MiniLM-L6-v2).

\vspace{0.2cm}
\textbf{Cost Calculation:} Based on HuggingFace API pricing per 1K tokens.
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{LLM Comparison - Qualitative Evaluation}
\begin{columns}
\begin{column}{0.33\textwidth}
\textbf{Gemma-2-2B}
\begin{itemize}
    \scriptsize
    \item Fastest response
    \item Concise answers
    \item Sometimes incomplete
    \item Good for simple queries
\end{itemize}
\end{column}

\begin{column}{0.33\textwidth}
\textbf{Mistral-7B}
\begin{itemize}
    \scriptsize
    \item Balanced performance
    \item Good reasoning
    \item Handles complex queries
    \item Best cost/quality ratio
\end{itemize}
\end{column}

\begin{column}{0.33\textwidth}
\textbf{LLaMA-3.1-8B}
\begin{itemize}
    \scriptsize
    \item Most detailed
    \item Best accuracy
    \item Higher latency
    \item Best for complex tasks
\end{itemize}
\end{column}
\end{columns}

\vspace{0.5cm}
\begin{center}
\begin{tikzpicture}
    \draw[->] (0,0) -- (8,0) node[right] {Quality};
    \draw[->] (0,0) -- (0,3) node[above] {Speed};

    \node[circle, fill=green!50, minimum size=0.6cm] at (2,2.5) {};
    \node[below] at (2,2) {\scriptsize Gemma};

    \node[circle, fill=blue!50, minimum size=0.6cm] at (5,1.5) {};
    \node[below] at (5,1) {\scriptsize Mistral};

    \node[circle, fill=red!50, minimum size=0.6cm] at (7,0.8) {};
    \node[below] at (7,0.3) {\scriptsize LLaMA};
\end{tikzpicture}
\end{center}
\end{frame}

%==============================================================================
% SECTION 6: ERROR ANALYSIS & IMPROVEMENTS
%==============================================================================
\section{Error Analysis \& Improvements}

\begin{frame}{Error Analysis \& Improvements}
\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Identified Issues:}
\begin{enumerate}
    \item \textbf{Entity Extraction}
    \begin{itemize}
        \scriptsize
        \item Hotel names with special chars missed
        \item Age group detection inconsistent
    \end{itemize}

    \item \textbf{Intent Classification}
    \begin{itemize}
        \scriptsize
        \item Confusion between search/recommendation
        \item Multi-intent queries not handled
    \end{itemize}

    \item \textbf{Graph Retrieval}
    \begin{itemize}
        \scriptsize
        \item Empty results for rare cities
        \item Slow for complex traversals
    \end{itemize}
\end{enumerate}
\end{column}

\begin{column}{0.5\textwidth}
\textbf{Improvements Made:}
\begin{enumerate}
    \item \textbf{Entity Extraction}
    \begin{itemize}
        \scriptsize
        \item Added rating keywords (cleanliness, comfort)
        \item Expanded traveller type vocabulary
    \end{itemize}

    \item \textbf{Intent Classification}
    \begin{itemize}
        \scriptsize
        \item Increased training data per class
        \item Added confidence threshold
    \end{itemize}

    \item \textbf{Embedding Retrieval}
    \begin{itemize}
        \scriptsize
        \item Dual approach (Node2Vec + Text)
        \item FAISS for fast similarity search
    \end{itemize}
\end{enumerate}
\end{column}
\end{columns}

\vspace{0.3cm}
\textbf{Future Work:} Multi-intent support, caching layer, conversation memory
\end{frame}

%==============================================================================
% SECTION 7: LIVE DEMO
%==============================================================================
\section{Live Demo}

\begin{frame}{Pipeline Recap for Demo}
\begin{center}
\begin{tikzpicture}[node distance=0.8cm, scale=0.75, transform shape,
    pstep/.style={rectangle, draw, fill=blue!20, text width=3cm, text centered, minimum height=0.7cm, rounded corners}]

    \node[pstep, fill=green!30] (s1) {1. User Query};
    \node[pstep, right=of s1] (s2) {2. BERT Intent};
    \node[pstep, right=of s2] (s3) {3. spaCy Entities};
    \node[pstep, right=of s3] (s4) {4. Query Embed};

    \node[pstep, below=0.8cm of s1, fill=orange!30] (s5) {5. Cypher Select};
    \node[pstep, right=of s5, fill=orange!30] (s6) {6. Neo4j Query};
    \node[pstep, right=of s6, fill=purple!30] (s7) {7. FAISS Search};
    \node[pstep, right=of s7, fill=yellow!30] (s8) {8. Context Build};

    \node[pstep, below=0.8cm of s5, fill=red!30] (s9) {9. LLM Generate};
    \node[pstep, right=of s9, fill=green!30] (s10) {10. Response};

    \draw[->, thick] (s1) -- (s2);
    \draw[->, thick] (s2) -- (s3);
    \draw[->, thick] (s3) -- (s4);
    \draw[->, thick] (s4) -- (s5);
    \draw[->, thick] (s5) -- (s6);
    \draw[->, thick] (s6) -- (s7);
    \draw[->, thick] (s7) -- (s8);
    \draw[->, thick] (s8) -- (s9);
    \draw[->, thick] (s9) -- (s10);

\end{tikzpicture}
\end{center}

\vspace{0.3cm}
\textbf{Demo Features:}
\begin{itemize}
    \item Switch between embedding models (Node2Vec / Text)
    \item Switch between LLMs (Gemma / Mistral / LLaMA)
    \item Real-time pipeline visualization
    \item Streamlit UI showing each processing step
\end{itemize}
\end{frame}

%------------------------------------------------------------------------------
\begin{frame}{Demo Queries}
\textbf{Test Queries for Live Demo:}

\begin{enumerate}
    \item \textbf{Recommendation:} ``Recommend me a good hotel in Tokyo''

    \item \textbf{Traveller Preference:} ``Best hotels for solo female travelers''

    \item \textbf{Visa Query:} ``Do I need a visa to travel from India to Dubai?''

    \item \textbf{Rating Filter:} ``Hotels with cleanliness rating above 9''

    \item \textbf{Comparison:} ``Compare The Azure Tower and Marina Bay''

    \item \textbf{Complex:} ``Find comfortable business hotels in Paris for travelers aged 25-34''
\end{enumerate}

\vspace{0.3cm}
\begin{center}
\textbf{[LIVE DEMO]}
\end{center}
\end{frame}

%==============================================================================
\begin{frame}
\begin{center}
\Huge Thank You!

\vspace{1cm}
\Large Questions?
\end{center}
\end{frame}

\end{document}
